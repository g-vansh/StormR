# Create a SpatialPoints object from the storm data
storm_points <- SpatialPoints(df[, c("Longitude", "Latitude")], proj4string = CRS("+proj=longlat +datum=WGS84"))
# Determine if the storm made landfall in the US using point.in.polygon()
landfall <- point.in.polygon(storm_points@coords[, 1], storm_points@coords[, 2],
us_poly@polygons[[1]]@Polygons[[1]]@coords[, 1],
us_poly@polygons[[1]]@Polygons[[1]]@coords[, 2])
if (sum(landfall) > 0){
landfall <- TRUE
} else {
landfall <- FALSE
}
# Return TRUE if the storm made landfall in the US, FALSE otherwise
return(landfall)
}
# Load the data
load("data/hurdat.rda")
# Filter the data to only include StormID "AL011851"
storm <- subset(hurdat, StormID == "AL061851")
# Determine if the storm made landfall in the US
made_landfall_US(storm)
#' Determine if the Storm Made Landfall in the United States
#'
#' A function for determining whether the storm made landfall in the
#' continental United States based on its latitude and longitude values.
#'
#' @param df A dataframe containing the storm data for a single storm
#' @return TRUE if the storm made landfall in the continental United States, FALSE otherwise
#' @export
made_landfall_US <- function(df){
library(maptools)
library(maps)
library(sp)
# Get the US map data from the maps package
us_map <- maps::map("state", plot = FALSE, fill = TRUE)
# Remove Hawaii and Alaska from the map data
# us_map <- us_map[!us_map$names %in% c("hawaii", "alaska"), ]
# Create a polygon object from the map data
us_poly <- maptools::map2SpatialPolygons(us_map, IDs = us_map$names, proj4string = CRS("+proj=longlat +datum=WGS84"))
# Create a SpatialPoints object from the storm data
storm_points <- SpatialPoints(df[, c("Longitude", "Latitude")], proj4string = CRS("+proj=longlat +datum=WGS84"))
# Determine if the storm made landfall in the US using point.in.polygon()
landfall <- point.in.polygon(storm_points@coords[, 1], storm_points@coords[, 2],
us_poly@polygons[[1]]@Polygons[[1]]@coords[, 1],
us_poly@polygons[[1]]@Polygons[[1]]@coords[, 2])
if (sum(landfall) > 0){
landfall <- TRUE
} else {
landfall <- FALSE
}
# Return TRUE if the storm made landfall in the US, FALSE otherwise
return(landfall)
}
# Load the data
load("data/hurdat.rda")
# Filter the data to only include StormID "AL011851"
storm <- subset(hurdat, StormID == "AL041851")
# Determine if the storm made landfall in the US
made_landfall_US(storm)
#' Determine if the Storm Made Landfall in the United States
#'
#' A function for determining whether the storm made landfall in the
#' continental United States based on its latitude and longitude values.
#'
#' @param df A dataframe containing the storm data for a single storm
#' @return TRUE if the storm made landfall in the continental United States, FALSE otherwise
#' @export
made_landfall_US <- function(df){
library(maptools)
library(maps)
library(sp)
# Get the US map data from the maps package
us_map <- maps::map("state", plot = FALSE, fill = TRUE)
# Remove Hawaii and Alaska from the map data
# us_map <- us_map[!us_map$names %in% c("hawaii", "alaska"), ]
# Create a polygon object from the map data
us_poly <- maptools::map2SpatialPolygons(us_map, IDs = us_map$names, proj4string = CRS("+proj=longlat +datum=WGS84"))
# Create a SpatialPoints object from the storm data
storm_points <- SpatialPoints(df[, c("Longitude", "Latitude")], proj4string = CRS("+proj=longlat +datum=WGS84"))
# Determine if the storm made landfall in the US using point.in.polygon()
landfall <- point.in.polygon(storm_points@coords[, 1], storm_points@coords[, 2],
us_poly@polygons[[1]]@Polygons[[1]]@coords[, 1],
us_poly@polygons[[1]]@Polygons[[1]]@coords[, 2])
if (sum(landfall) > 0){
landfall <- TRUE
} else {
landfall <- FALSE
}
# Return TRUE if the storm made landfall in the US, FALSE otherwise
return(landfall)
}
# Load the data
load("data/hurdat.rda")
# Filter the data to only include StormID "AL011851"
storm <- subset(hurdat, StormID == "AL011851")
# Determine if the storm made landfall in the US
made_landfall_US(storm)
#' Determine if the Storm Made Landfall in the United States
#'
#' A function for determining whether the storm made landfall in the
#' continental United States based on its latitude and longitude values.
#'
#' @param df A dataframe containing the storm data for a single storm
#' @return TRUE if the storm made landfall in the continental United States, FALSE otherwise
#' @export
made_landfall_US <- function(df){
library(maptools)
library(maps)
library(sp)
# Get the US map data from the maps package
us_map <- maps::map("state", plot = FALSE, fill = TRUE)
# Remove Hawaii and Alaska from the map data
# us_map <- us_map[!us_map$names %in% c("hawaii", "alaska"), ]
# Create a polygon object from the map data
us_poly <- maptools::map2SpatialPolygons(us_map, IDs = us_map$names, proj4string = CRS("+proj=longlat +datum=WGS84"))
# Create a SpatialPoints object from the storm data
storm_points <- SpatialPoints(df[, c("Longitude", "Latitude")], proj4string = CRS("+proj=longlat +datum=WGS84"))
# Determine if the storm made landfall in the US
landfall <- over(storm_points, us_poly)
if (sum(landfall) > 0){
landfall <- TRUE
} else {
landfall <- FALSE
}
# Return TRUE if the storm made landfall in the US, FALSE otherwise
return(landfall)
}
# Load the data
load("data/hurdat.rda")
# Filter the data to only include StormID "AL011851"
storm <- subset(hurdat, StormID == "AL011851")
# Determine if the storm made landfall in the US
made_landfall_US(storm)
#' Determine if the Storm Made Landfall in the United States
#'
#' A function for determining whether the storm made landfall in the
#' continental United States based on its latitude and longitude values.
#'
#' @param df A dataframe containing the storm data for a single storm
#' @return TRUE if the storm made landfall in the continental United States, FALSE otherwise
#' @export
made_landfall_US <- function(df){
library(maptools)
library(maps)
library(sp)
# Get the US map data from the maps package
us_map <- maps::map("state", plot = FALSE, fill = TRUE)
# Remove Hawaii and Alaska from the map data
# us_map <- us_map[!us_map$names %in% c("hawaii", "alaska"), ]
# Create a polygon object from the map data
us_poly <- maptools::map2SpatialPolygons(us_map, IDs = us_map$names, proj4string = CRS("+proj=longlat +datum=WGS84"))
# Create a SpatialPoints object from the storm data
storm_points <- SpatialPoints(df[, c("Longitude", "Latitude")], proj4string = CRS("+proj=longlat +datum=WGS84"))
# Determine if the storm made landfall in the US
landfall <- over(storm_points, us_poly)
print(landfall)
if (sum(landfall) > 0){
landfall <- TRUE
} else {
landfall <- FALSE
}
# Return TRUE if the storm made landfall in the US, FALSE otherwise
return(landfall)
}
# Load the data
load("data/hurdat.rda")
# Filter the data to only include StormID "AL011851"
storm <- subset(hurdat, StormID == "AL011851")
# Determine if the storm made landfall in the US
made_landfall_US(storm)
View(hurdat)
#' Determine if the Storm Made Landfall in the United States
#'
#' A function for determining whether the storm made landfall in the
#' continental United States based on its latitude and longitude values.
#'
#' @param df A dataframe containing the storm data for a single storm
#' @return TRUE if the storm made landfall in the continental United States, FALSE otherwise
#' @export
made_landfall_US <- function(df){
library(maptools)
library(maps)
library(sp)
# Get the US map data from the maps package
us_map <- maps::map("state", plot = FALSE, fill = TRUE)
# Remove Hawaii and Alaska from the map data
# us_map <- us_map[!us_map$names %in% c("hawaii", "alaska"), ]
# Create a polygon object from the map data
us_poly <- maptools::map2SpatialPolygons(us_map, IDs = us_map$names, proj4string = CRS("+proj=longlat +datum=WGS84"))
# Create a SpatialPoints object from the storm data
storm_points <- SpatialPoints(df[, c("Longitude", "Latitude")], proj4string = CRS("+proj=longlat +datum=WGS84"))
# Determine if the storm made landfall in the US
landfall <- sp::over(storm_points, us_poly)
print(landfall)
if (sum(landfall) > 0){
landfall <- TRUE
} else {
landfall <- FALSE
}
# Return TRUE if the storm made landfall in the US, FALSE otherwise
return(landfall)
}
# Load the data
load("data/hurdat.rda")
# Filter the data to only include StormID "AL011851"
storm <- subset(hurdat, StormID == "AL021851")
# Determine if the storm made landfall in the US
made_landfall_US(storm)
#' Determine if the Storm Made Landfall in the United States
#'
#' A function for determining whether the storm made landfall in the
#' continental United States based on its latitude and longitude values.
#'
#' @param df A dataframe containing the storm data for a single storm
#' @return TRUE if the storm made landfall in the continental United States, FALSE otherwise
#' @export
made_landfall_US <- function(df){
library(maptools)
library(maps)
library(sp)
# Get the US map data from the maps package
us_map <- maps::map("state", plot = FALSE, fill = TRUE)
# Remove Hawaii and Alaska from the map data
# us_map <- us_map[!us_map$names %in% c("hawaii", "alaska"), ]
# Create a polygon object from the map data
us_poly <- maptools::map2SpatialPolygons(us_map, IDs = us_map$names, proj4string = CRS("+proj=longlat +datum=WGS84"))
# Create a SpatialPoints object from the storm data
storm_points <- SpatialPoints(df[, c("Longitude", "Latitude")], proj4string = CRS("+proj=longlat +datum=WGS84"))
# Determine if the storm made landfall in the US
landfall <- sp::over(storm_points, us_poly)
# Replace all NA values with 0
landfall[is.na(landfall)] <- 0
if (sum(landfall) > 0){
landfall <- TRUE
} else {
landfall <- FALSE
}
# Return TRUE if the storm made landfall in the US, FALSE otherwise
return(landfall)
}
# Load the data
load("data/hurdat.rda")
# Filter the data to only include StormID "AL011851"
storm <- subset(hurdat, StormID == "AL021851")
# Determine if the storm made landfall in the US
made_landfall_US(storm)
#' Determine if the Storm Made Landfall in the United States
#'
#' A function for determining whether the storm made landfall in the
#' continental United States based on its latitude and longitude values.
#'
#' @param df A dataframe containing the storm data for a single storm
#' @return TRUE if the storm made landfall in the continental United States, FALSE otherwise
#' @export
made_landfall_US <- function(df){
library(maptools)
library(maps)
library(sp)
# Get the US map data from the maps package
us_map <- maps::map("state", plot = FALSE, fill = TRUE)
# Remove Hawaii and Alaska from the map data
# us_map <- us_map[!us_map$names %in% c("hawaii", "alaska"), ]
# Create a polygon object from the map data
us_poly <- maptools::map2SpatialPolygons(us_map, IDs = us_map$names, proj4string = CRS("+proj=longlat +datum=WGS84"))
# Create a SpatialPoints object from the storm data
storm_points <- SpatialPoints(df[, c("Longitude", "Latitude")], proj4string = CRS("+proj=longlat +datum=WGS84"))
# Determine if the storm made landfall in the US
landfall <- sp::over(storm_points, us_poly)
# Replace all NA values with 0
landfall[is.na(landfall)] <- 0
if (sum(landfall) > 0){
landfall <- TRUE
} else {
landfall <- FALSE
}
# Return TRUE if the storm made landfall in the US, FALSE otherwise
return(landfall)
}
# Load the data
load("data/hurdat.rda")
# Filter the data to only include StormID "AL011851"
storm <- subset(hurdat, StormID == "AL011851")
# Determine if the storm made landfall in the US
made_landfall_US(storm)
View(hurdat)
#' Calculate the Accumulated Cyclone Energy of a Storm
#'
#' This function computes the accumulated cyclone energy of a given storm.
#'
#' @param df A dataframe containing the storm data for a single storm.
#' @return A numeric value representing the accumulated cyclone energy of the storm.
#' @export
calculate_cyclone_energy <- function(df){
# Get the date and time of the first observation
first_time <- as.POSIXct(paste(toString(df$Date[i]), toString(df$Time[i]), sep = ""), format = "%Y%m%d%H%M")
# Loop through each row, and keep only the times that are 6 hours apart
for(i in 2:nrow(df)){
# Get the date and time of the current observation
current_time <- as.POSIXct(paste(toString(df$Date[i]), toString(df$Time[i]), sep = ""), format = "%Y%m%d%H%M")
# Calculate the time difference between the current observation and the first observation
time_diff <- as.numeric(difftime(current_time, first_time, units = "mins"))
# If the time difference is a multiple of 6, keep the row
if(time_diff >= 360){
df_interpolated <- rbind(df_interpolated, data.frame(df[i,]))
first_time <- current_time
}
}
# Initialise energy sum
energy_sum <- 0
# Loop through the 50 kt wind radii columns and sum their squares
direction_list <- c("NE", "SE", "SW", "NW")
for(i in 1:4){
energy_sum <- energy_sum + sum(df[ ,paste("50", direction_list[i], sep = "")]^2)
energy_sum <- energy_sum + sum(df[ ,paste("64", direction_list[i], sep = "")]^2)
}
# Calculate the cyclone energy
cyclone_energy <- energy_sum / 10000
# Return the cyclone energy
return(cyclone_energy)
}
# Load the dataset
load("data/hurdat.rda")
# Subset hurdat to StormID AL012021
hurdat <- hurdat[hurdat$StormID == "AL212021", ]
# Calculate the cyclone energy
cyclone_energy <- calculate_cyclone_energy(hurdat)
#' Calculate the Accumulated Cyclone Energy of a Storm
#'
#' This function computes the accumulated cyclone energy of a given storm.
#'
#' @param df A dataframe containing the storm data for a single storm.
#' @return A numeric value representing the accumulated cyclone energy of the storm.
#' @export
calculate_cyclone_energy <- function(df){
# Get the date and time of the first observation
first_time <- as.POSIXct(paste(toString(df$Date[1]), toString(df$Time[1]), sep = ""), format = "%Y%m%d%H%M")
# Loop through each row, and keep only the times that are 6 hours apart
for(i in 2:nrow(df)){
# Get the date and time of the current observation
current_time <- as.POSIXct(paste(toString(df$Date[i]), toString(df$Time[i]), sep = ""), format = "%Y%m%d%H%M")
# Calculate the time difference between the current observation and the first observation
time_diff <- as.numeric(difftime(current_time, first_time, units = "mins"))
# If the time difference is a multiple of 6, keep the row
if(time_diff >= 360){
df_interpolated <- rbind(df_interpolated, data.frame(df[i,]))
first_time <- current_time
}
}
# Initialise energy sum
energy_sum <- 0
# Loop through the 50 kt wind radii columns and sum their squares
direction_list <- c("NE", "SE", "SW", "NW")
for(i in 1:4){
energy_sum <- energy_sum + sum(df[ ,paste("50", direction_list[i], sep = "")]^2)
energy_sum <- energy_sum + sum(df[ ,paste("64", direction_list[i], sep = "")]^2)
}
# Calculate the cyclone energy
cyclone_energy <- energy_sum / 10000
# Return the cyclone energy
return(cyclone_energy)
}
# Load the dataset
load("data/hurdat.rda")
# Subset hurdat to StormID AL012021
hurdat <- hurdat[hurdat$StormID == "AL212021", ]
# Calculate the cyclone energy
cyclone_energy <- calculate_cyclone_energy(hurdat)
#' Calculate the Accumulated Cyclone Energy of a Storm
#'
#' This function computes the accumulated cyclone energy of a given storm.
#'
#' @param df A dataframe containing the storm data for a single storm.
#' @return A numeric value representing the accumulated cyclone energy of the storm.
#' @export
calculate_cyclone_energy <- function(df){
# Create a new dataframe to store the collapsed data
df_collapsed <- data.frame()
# Get the date and time of the first observation
first_time <- as.POSIXct(paste(toString(df$Date[1]), toString(df$Time[1]), sep = ""), format = "%Y%m%d%H%M")
# Add the first row to the dataframe
df_collapsed <- rbind(df_collapsed, data.frame(df[1,]))
# Loop through each row, and keep only the times that are 6 hours apart
for(i in 2:nrow(df)){
# Get the date and time of the current observation
current_time <- as.POSIXct(paste(toString(df$Date[i]), toString(df$Time[i]), sep = ""), format = "%Y%m%d%H%M")
# Calculate the time difference between the current observation and the first observation
time_diff <- as.numeric(difftime(current_time, first_time, units = "mins"))
# If the time difference is a multiple of 6, keep the row
if(time_diff >= 360){
df_collapsed <- rbind(df_collapsed, data.frame(df[i,]))
first_time <- current_time
}
}
# Initialise energy sum
energy_sum <- 0
# Loop through the 50 kt wind radii columns and sum their squares
direction_list <- c("NE", "SE", "SW", "NW")
for(i in 1:4){
energy_sum <- energy_sum + sum(df[ ,paste("50", direction_list[i], sep = "")]^2)
energy_sum <- energy_sum + sum(df[ ,paste("64", direction_list[i], sep = "")]^2)
}
# Calculate the cyclone energy
cyclone_energy <- energy_sum / 10000
# Return the cyclone energy
return(cyclone_energy)
}
# Load the dataset
load("data/hurdat.rda")
# Subset hurdat to StormID AL012021
hurdat <- hurdat[hurdat$StormID == "AL212021", ]
# Calculate the cyclone energy
cyclone_energy <- calculate_cyclone_energy(hurdat)
View(hurdat)
#' Calculate the Accumulated Cyclone Energy of a Storm
#'
#' This function computes the accumulated cyclone energy of a given storm.
#'
#' @param df A dataframe containing the storm data for a single storm.
#' @return A numeric value representing the accumulated cyclone energy of the storm.
#' @export
calculate_cyclone_energy <- function(df){
# Create a new dataframe to store the collapsed data
df_collapsed <- data.frame()
# Get the date and time of the first observation
first_time <- as.POSIXct(paste(toString(df$Date[1]), toString(df$Time[1]), sep = ""), format = "%Y%m%d%H%M")
# Add the first row to the dataframe
df_collapsed <- rbind(df_collapsed, data.frame(df[1,]))
# Loop through each row, and keep only the times that are 6 hours apart
for(i in 2:nrow(df)){
# Get the date and time of the current observation
current_time <- as.POSIXct(paste(toString(df$Date[i]), toString(df$Time[i]), sep = ""), format = "%Y%m%d%H%M")
# Calculate the time difference between the current observation and the first observation
time_diff <- as.numeric(difftime(current_time, first_time, units = "mins"))
# If the time difference is a multiple of 6, keep the row
if(time_diff >= 360){
df_collapsed <- rbind(df_collapsed, data.frame(df[i,]))
first_time <- current_time
}
}
# Initialise energy sum
energy_sum <- 0
# Loop through the 50 kt wind radii columns and sum their squares
direction_list <- c("NE", "SE", "SW", "NW")
for(i in 1:4){
energy_sum <- energy_sum + sum(df[ ,paste("50", direction_list[i], sep = "")]^2)
energy_sum <- energy_sum + sum(df[ ,paste("64", direction_list[i], sep = "")]^2)
}
# Calculate the cyclone energy
cyclone_energy <- energy_sum / 10000
# Return the cyclone energy
return(cyclone_energy)
}
# Load the dataset
load("data/hurdat.rda")
# Subset hurdat to StormID AL012021
hurdat <- hurdat[hurdat$StormName == "MATTHEW", ]
# Calculate the cyclone energy
cyclone_energy <- calculate_cyclone_energy(hurdat)
View(hurdat)
#' Calculate the Accumulated Cyclone Energy of a Storm
#'
#' This function computes the accumulated cyclone energy of a given storm.
#'
#' @param df A dataframe containing the storm data for a single storm.
#' @return A numeric value representing the accumulated cyclone energy of the storm.
#' @export
calculate_cyclone_energy <- function(df){
# Create a new dataframe to store the collapsed data
df_collapsed <- data.frame()
# Get the date and time of the first observation
first_time <- as.POSIXct(paste(toString(df$Date[1]), toString(df$Time[1]), sep = ""), format = "%Y%m%d%H%M")
# Add the first row to the dataframe
df_collapsed <- rbind(df_collapsed, data.frame(df[1,]))
# Loop through each row, and keep only the times that are 6 hours apart
for(i in 2:nrow(df)){
# Get the date and time of the current observation
current_time <- as.POSIXct(paste(toString(df$Date[i]), toString(df$Time[i]), sep = ""), format = "%Y%m%d%H%M")
# Calculate the time difference between the current observation and the first observation
time_diff <- as.numeric(difftime(current_time, first_time, units = "mins"))
# If the time difference is a multiple of 6, keep the row
if(time_diff >= 360){
df_collapsed <- rbind(df_collapsed, data.frame(df[i,]))
first_time <- current_time
}
}
# Initialise energy sum
energy_sum <- 0
# Loop through the 50 kt wind radii columns and sum their squares
direction_list <- c("NE", "SE", "SW", "NW")
for(i in 1:4){
energy_sum <- energy_sum + sum(df[ ,paste("50", direction_list[i], sep = "")]^2)
energy_sum <- energy_sum + sum(df[ ,paste("64", direction_list[i], sep = "")]^2)
}
# Calculate the cyclone energy
cyclone_energy <- energy_sum / 10000
# Return the cyclone energy
return(cyclone_energy)
}
# Load the dataset
load("data/hurdat.rda")
# Subset hurdat to StormID AL012021
hurdat <- hurdat[hurdat$StormID == "AL142016", ]
# Calculate the cyclone energy
cyclone_energy <- calculate_cyclone_energy(hurdat)
View(hurdat)
library(devtools)
build()
devtools::check()
install.packages("Rtools")
devtools::check()
devtools::check()
devtools::check()
devtools::check()
